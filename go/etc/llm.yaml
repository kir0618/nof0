base_url: "https://zenmux.ai/api/v1"
api_key: "${ZENMUX_API_KEY}"
# Default model used at runtime. In unit tests you can enable low-cost
# overrides via environment variables without changing this file:
#   - LLM_TEST_MODE=1
#   - LLM_TEST_MODEL or LLM_TEST_MODEL_LIST
default_model: "gpt-5"
timeout: "60s"
max_retries: 3
log_level: "info"

# Note: Zenmux auto-routing is currently unstable. Test mode uses a fixed
# low-cost model (minimax/minimax-m2) instead. This may change in the future.

models:
  gpt-5:
    provider: "openai"
    model_name: "openai/gpt-5"
    temperature: 0.7
    max_completion_tokens: 4096
    priority: 1
    cost_tier: high
  claude-sonnet-4.5:
    provider: "anthropic"
    model_name: "anthropic/claude-sonnet-4.5"
    temperature: 0.7
    max_completion_tokens: 4096
    priority: 2
    cost_tier: high
  deepseek-chat:
    provider: "deepseek"
    model_name: "deepseek/deepseek-chat-v3.1"
    temperature: 0.6
    max_completion_tokens: 4096
    priority: 3
    cost_tier: medium

budget:
  daily_token_limit: 500000
  alert_threshold_pct: 80
  strict_enforcement: true
  cost_per_million_tokens:
    gpt-5: 18.0
    claude-sonnet-4.5: 16.0
    deepseek-chat: 2.0
